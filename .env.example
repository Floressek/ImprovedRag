# ====================================
# RAGx Environment Configuration
# ====================================

# --- Qdrant Vector Database ---
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION=ragx_documents_v2

# --- Model Configuration ---
# Embedding model (GTE multilingual for PL/EN support)
EMBEDDING_MODEL=Alibaba-NLP/gte-multilingual-base
EMBEDDING_BATCH_SIZE=64
EMBEDDING_MAX_SEQ_LENGTH=512
USE_EMBEDDING_PREFIXES=true

# Reranker model (Jina multilingual)
RERANKER_MODEL=jinaai/jina-reranker-v2-base-multilingual
RERANKER_BATCH_SIZE=16

# LLM model (Qwen2.5 for better PL/EN performance)
LLM_MODEL=Qwen/Qwen2.5-7B-Instruct
LLM_LOAD_IN_4BIT=true
LLM_MAX_NEW_TOKENS=300
LLM_TEMPERATURE=0.2

# --- Retrieval Configuration ---
TOP_K_RETRIEVE=80
RERANK_TOP_M=50
CONTEXT_TOP_N=6
CHUNK_SIZE=512
CHUNK_OVERLAP=96
CHUNKING_STRATEGY=semantic

# --- HNSW Index Configuration ---
HNSW_M=32
HNSW_EF_CONSTRUCT=256
HNSW_ON_DISK=true
HNSW_SEARCH_EF=128

# --- Data Paths ---
DATA_DIR=./data
RAW_DATA_DIR=./data/raw
PROCESSED_DATA_DIR=./data/processed
INDICES_DIR=./data/indices
MODEL_CACHE_DIR=./models/cache

# --- API Configuration ---
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1
API_RELOAD=false

# --- GPU Configuration ---
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# --- HuggingFace ---
HF_HOME=./models/huggingface
TRANSFORMERS_CACHE=./models/transformers