# ─────────────────────────────────────────────────────────────────────────────
# APP / LOGGING
# ─────────────────────────────────────────────────────────────────────────────
APP_ENV=development
LOG_LEVEL=INFO

# ─────────────────────────────────────────────────────────────────────────────
# PATHS
# ─────────────────────────────────────────────────────────────────────────────
DATA_DIR=./data
RAW_DATA_DIR=./data/raw
PROCESSED_DATA_DIR=./data/processed
INDEX_DIR=./data/index
INDICES_DIR=./data/indices
MODEL_CACHE_DIR=./models/cache

# ─────────────────────────────────────────────────────────────────────────────
# QDRANT (vector store)
# ─────────────────────────────────────────────────────────────────────────────
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=ragx_documents_1M_main_sample
QDRANT_EMBEDDING_DIM=768
QDRANT_DISTANCE_METRIC=cosine
QDRANT_TIMEOUT_S=60
QDRANT_RECREATE_COLLECTION=false
QDRANT_MAX_RETRIES=3
QDRANT_RETRY_DELAY=2.0

# ─────────────────────────────────────────────────────────────────────────────
# EMBEDDINGS
# ─────────────────────────────────────────────────────────────────────────────
EMBEDDING_MODEL=Alibaba-NLP/gte-multilingual-base
EMBEDDING_DEVICE=cuda
EMBEDDING_BATCH_SIZE=126
EMBEDDING_MAX_SEQ_LENGTH=512
EMBEDDING_NORMALIZE=true
EMBEDDING_SHOW_PROGRESS=true
EMBEDDING_USE_PREFIXES=true
# (domyślnie w settings są spacje po dwukropku)
EMBEDDING_QUERY_PREFIX=query:
EMBEDDING_PASSAGE_PREFIX=passage:

# ─────────────────────────────────────────────────────────────────────────────
# CHUNKER
# ─────────────────────────────────────────────────────────────────────────────
CHUNKER_STRATEGY=semantic
CHUNKER_CHUNK_SIZE=512
CHUNKER_CHUNK_OVERLAP=128
CHUNKER_MIN_CHUNK_SIZE=150
CHUNKER_MAX_CHUNK_SIZE=512
CHUNKER_RESPECT_SECTIONS=true
CHUNKER_BREAKPOINT_PERCENTILE_THRESHOLD=84
CHUNKER_BUFFER_SIZE=7
CHUNKER_ADD_PASSAGE_PREFIX=false
CHUNKER_CONTEXT_TAIL_TOKENS=0
CHUNKER_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# ─────────────────────────────────────────────────────────────────────────────
# RERANKER
# ─────────────────────────────────────────────────────────────────────────────
RERANKER_MODEL=jinaai/jina-reranker-v2-base-multilingual
RERANKER_DEVICE=auto
RERANKER_BATCH_SIZE=16
RERANKER_MAX_LENGTH=512
RERANKER_SHOW_PROGRESS=false

# ─────────────────────────────────────────────────────────────────────────────
# RETRIEVAL / RANKING BUDGETS
# ─────────────────────────────────────────────────────────────────────────────
TOP_K_RETRIEVE=200
CONTEXT_TOP_N=8
RERANK_TOP_M=8

# ─────────────────────────────────────────────────────────────────────────────
# REWRITE
# ─────────────────────────────────────────────────────────────────────────────
REWRITE_MAX_TOKENS=6048
REWRITE_TEMPERATURE=0.2
REWRITE_ENABLED=true
REWRITE_VERIFY_BEFORE_RETRIEVAL=false

# ─────────────────────────────────────────────────────────────────────────────
# LLM (provider selection + local Ollama)
# ─────────────────────────────────────────────────────────────────────────────
LLM_MODEL=Qwen/Qwen3-8B-Instruct
LLM_MODEL_NAME_OLLAMA=qwen3:14b
LLM_PROVIDER=ollama
OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODELS_PATH (opcjonalne) – zostaw puste jeśli nie używasz
# OLLAMA_MODELS_PATH=E:\Models\Ollama\.ollama\models

# ─────────────────────────────────────────────────────────────────────────────
# LLM – parametry wspólne
# ─────────────────────────────────────────────────────────────────────────────
LLM_MAX_NEW_TOKENS=16384
LLM_DEVICE=cuda
LLM_LOAD_IN_4BIT=true
LLM_TEMPERATURE=0.2
LLM_TOP_P=0.9
REPETITION_PENALTY=1.1

# ─────────────────────────────────────────────────────────────────────────────
# LLM (HTTP API – używane, gdy LLM_PROVIDER ≠ ollama)
# ─────────────────────────────────────────────────────────────────────────────
LLM_API_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1
LLM_API_KEY=...
LLM_API_MODEL_NAME=qwen3-32b

# ─────────────────────────────────────────────────────────────────────────────
# vLLM (ignorowane, gdy LLM_PROVIDER=ollama)
# ─────────────────────────────────────────────────────────────────────────────
TENSOR_PARALLEL_SIZE=1
GPU_MEMORY_UTILIZATION=0.9
TRUST_REMOTE_CODE=true
QUANTIZATION=awq
MAX_MODEL_LEN=8192

# ─────────────────────────────────────────────────────────────────────────────
# CoVe (Chain-of-Verification)
# ─────────────────────────────────────────────────────────────────────────────
COVE_ENABLED=true
COVE_PERFORM_CORRECTION=true
# Correction modes:
#   auto     - Automatically correct false claims (best for API models 32B+)
#   suggest  - LLM suggests corrections, system decides based on confidence (good for 14B+ models)
#   metadata - Only return uncertain claims in metadata, don't auto-correct (safest for 8B models)
COVE_CORRECTION_MODE=metadata
COVE_CORRECTION_CONFIDENCE_THRESHOLD=0.8
COVE_INJECT_MISSING_CITATIONS=true
COVE_MAX_VERIFICATION=5
COVE_VERIFICATION_THRESHOLD=0.6
COVE_TEMPERATURE=0.2
COVE_MAX_TOKENS=8192
COVE_ENABLE_RECOVERY=true
COVE_MAX_TARGETED_QUERIES=8
COVE_CRITICAL_FAILURE_THRESHOLD=0.3
COVE_MISSING_EVIDENCE_THRESHOLD=0.5
COVE_USE_BATCH_NLI=true

# ─────────────────────────────────────────────────────────────────────────────
# HNSW (index)
# ─────────────────────────────────────────────────────────────────────────────
HNSW_M=32
HNSW_EF_CONSTRUCT=256
HNSW_ON_DISK=true
HNSW_SEARCH_EF=256

# ─────────────────────────────────────────────────────────────────────────────
# API SERVER
# ─────────────────────────────────────────────────────────────────────────────
API_HOST=0.0.0.0
API_PORT=8080
API_WORKERS=1
API_RELOAD=false

# ─────────────────────────────────────────────────────────────────────────────
# HUGGINGFACE CACHES
# ─────────────────────────────────────────────────────────────────────────────
HF_HOME=./models/huggingface
TRANSFORMERS_CACHE=./models/transformers
HF_HUB_CACHE=./models/hub

# ─────────────────────────────────────────────────────────────────────────────
# CHAT
# ─────────────────────────────────────────────────────────────────────────────
CHAT_MAX_HISTORY=10
CHAT_SYSTEM_PROMPT="You are a helpful assistant"
CHAT_CONTEXT_WINDOW=6096
CHAT_TEMPERATURE=0.7
CHAT_TOP_P=0.9
