# üß† Processed Wikipedia Data

This directory contains the **cleaned and tokenized Wikipedia corpus**, extracted from
the raw XML dump using `WikiExtractor`. The result is a structured dataset ready for
embedding generation and ingestion into the Qdrant vector database.

## Structure

```
processed/
‚îî‚îÄ‚îÄ wiki_extracted/
‚îú‚îÄ‚îÄ AA/
‚îÇ ‚îú‚îÄ‚îÄ wiki_00.jsonl
‚îÇ ‚îú‚îÄ‚îÄ wiki_01.jsonl
‚îÇ ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ AB/
‚îî‚îÄ‚îÄ ...
```

Each `.jsonl` file contains JSON-formatted articles with the following fields:

```json
{
  "id": "12345",
  "title": "Przyk≈Çad artyku≈Çu",
  "text": "Tre≈õƒá artyku≈Çu po ekstrakcji, bez znacznik√≥w HTML...",
  "url": "https://pl.wikipedia.org/wiki/Przyk≈Çad_artyku≈Çu"
}
```

## Generation

> ‚ö†Ô∏è The data was extracted automatically in a Docker container.

Resulting files are indexed and consumed by the embedding pipeline (src/ragx/ingestion)
to produce Qdrant vectors.

## License

- **Source:** [Polish Wikipedia](https://pl.wikipedia.org/)
- **Snapshot date:** 2025-06-01
- **License:** [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)
- **Processing tool:** `wikiextractor` (Dockerized)

> *Transformation: Text cleaned and chunked; metadata preserved.*

> ‚ö†Ô∏è **The processed files remain under the same CC BY-SA license as the source material.**
