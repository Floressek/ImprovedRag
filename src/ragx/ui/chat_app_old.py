from __future__ import annotations

import streamlit as st
import requests
import json
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import time
from datetime import datetime

try:
    import plotly.express as px
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
    px = None

# Page config
st.set_page_config(
    page_title="RAGx Chat",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ============================================================================
# CONFIGURATION PRESETS (from ablation_study.py)
# ============================================================================

@dataclass
class PipelineConfig:
    """Pipeline configuration preset."""
    name: str
    description: str
    query_analysis_enabled: bool = True
    cot_enabled: bool = True
    reranker_enabled: bool = True
    cove_mode: str = "off"
    prompt_template: str = "auto"
    top_k: int = 10

PRESETS = {
    "baseline": PipelineConfig(
        name="Baseline",
        description="üîµ No enhancements (vector search only)",
        query_analysis_enabled=False,
        cot_enabled=False,
        reranker_enabled=False,
        cove_mode="off",
        prompt_template="basic",
    ),
    "enhanced_full": PipelineConfig(
        name="Enhanced (Full)",
        description="üü¢ All enhancements enabled (no CoVe)",
        query_analysis_enabled=True,
        cot_enabled=True,
        reranker_enabled=True,
        cove_mode="auto",
        prompt_template="auto",
    ),
    "enhanced_cove": PipelineConfig(
        name="Enhanced + CoVe",
        description="üü£ Full pipeline with CoVe auto-correction",
        query_analysis_enabled=True,
        cot_enabled=True,
        reranker_enabled=True,
        cove_mode="auto",
        prompt_template="auto",
    ),
    "query_only": PipelineConfig(
        name="Query Analysis Only",
        description="üü° Multihop detection only",
        query_analysis_enabled=True,
        cot_enabled=False,
        reranker_enabled=False,
        cove_mode="off",
        prompt_template="basic",
    ),
    "reranker_only": PipelineConfig(
        name="Reranker Only",
        description="üü† Reranking only",
        query_analysis_enabled=False,
        cot_enabled=False,
        reranker_enabled=True,
        cove_mode="off",
        prompt_template="basic",
    ),
}

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def get_pipeline_steps(config: PipelineConfig) -> List[tuple]:
    """Get list of enabled pipeline steps with their messages."""
    all_steps = [
        ("query_analysis", "üîç Analyzing query", config.query_analysis_enabled),
        ("retrieval", "üì• Retrieving candidates", True),
        ("reranking", "üìä Reranking results", config.reranker_enabled),
        ("generation", "üí≠ Generating answer", True),
        ("cove", "‚úÖ Verifying with CoVe", config.cove_mode != "off"),
    ]

    # Number the enabled steps
    enabled_steps = [(k, msg, enabled) for k, msg, enabled in all_steps]
    enabled_count = sum(1 for _, _, enabled in enabled_steps if enabled)

    numbered_steps = []
    step_num = 1
    for key, msg, enabled in enabled_steps:
        if enabled:
            numbered_steps.append((key, f"**Step {step_num}/{enabled_count}:** {msg}...", True))
            step_num += 1
        else:
            numbered_steps.append((key, f"{msg} (skipped)", False))

    return numbered_steps


def call_rag_api(query: str, config: PipelineConfig, api_url: str) -> Dict[str, Any]:
    """Call RAG API with given config."""
    request_data = {
        "query": query,
        "use_query_analysis": config.query_analysis_enabled,
        "use_cot": config.cot_enabled,
        "use_reranker": config.reranker_enabled,
        "cove": config.cove_mode,
        "prompt_template": config.prompt_template,
        "top_k": config.top_k,
    }

    response = requests.post(
        f"{api_url}/eval/ablation",
        json=request_data,
        timeout=120,
    )
    response.raise_for_status()
    return response.json()


def update_session_stats(config_name: str, total_time_ms: float):
    """Update session statistics."""
    stats = st.session_state.session_stats
    stats["total_queries"] += 1
    stats["total_time_ms"] += total_time_ms

    if config_name not in stats["configs_used"]:
        stats["configs_used"][config_name] = 0
    stats["configs_used"][config_name] += 1

# ============================================================================
# SESSION STATE
# ============================================================================

if "messages" not in st.session_state:
    st.session_state.messages = []

if "api_url" not in st.session_state:
    st.session_state.api_url = "http://localhost:8080"

if "comparison_mode" not in st.session_state:
    st.session_state.comparison_mode = False

if "session_stats" not in st.session_state:
    st.session_state.session_stats = {
        "total_queries": 0,
        "total_time_ms": 0,
        "configs_used": {},
    }

if "example_query" not in st.session_state:
    st.session_state.example_query = None

# stan po≈ÇƒÖczenia ‚Äì tylko do wy≈õwietlania ostatniego wyniku health checka
if "connection_status" not in st.session_state:
    st.session_state.connection_status = {
        "status": None,   # "ok", "error", "unknown"
        "message": "Not checked yet",
    }

# ============================================================================
# SIDEBAR - CONFIGURATION
# ============================================================================

with st.sidebar:
    st.title("‚öôÔ∏è Configuration")

    # API URL
    api_url = st.text_input(
        "API URL",
        value=st.session_state.api_url,
        help="Base URL of the RAGx API server"
    )
    st.session_state.api_url = api_url

    st.divider()

    # Configuration Mode
    config_mode = st.radio(
        "Configuration Mode",
        options=["Presets", "Custom"],
        help="Use predefined presets or configure manually"
    )

    if config_mode == "Presets":
        preset_key = st.selectbox(
            "Select Pipeline",
            options=list(PRESETS.keys()),
            format_func=lambda x: PRESETS[x].name,
            help="Choose a predefined configuration"
        )

        preset = PRESETS[preset_key]
        st.info(preset.description)

        # Display current config
        with st.expander("üìã Configuration Details"):
            st.json({
                "query_analysis": preset.query_analysis_enabled,
                "cot": preset.cot_enabled,
                "reranker": preset.reranker_enabled,
                "cove_mode": preset.cove_mode,
                "prompt_template": preset.prompt_template,
                "top_k": preset.top_k,
            })

    else:  # Custom mode
        st.markdown("### Pipeline Toggles")

        query_analysis = st.checkbox(
            "üîç Query Analysis",
            value=True,
            help="Enable multihop detection and adaptive rewriting"
        )

        cot = st.checkbox(
            "üß† Chain of Thought",
            value=True,
            help="Enable step-by-step reasoning"
        )

        reranker = st.checkbox(
            "üìä Reranker",
            value=True,
            help="Enable semantic reranking"
        )

        cove_mode = st.selectbox(
            "‚úÖ CoVe Mode",
            options=["off", "auto", "metadata", "suggest"],
            help="Chain-of-Verification mode"
        )

        prompt_template = st.selectbox(
            "üìù Prompt Template",
            options=["auto", "basic", "enhanced"],
            help="Auto adapts based on query analysis"
        )

        top_k = st.slider(
            "üî¢ Top K",
            min_value=1,
            max_value=20,
            value=10,
            help="Number of contexts to retrieve"
        )

        # Create custom preset
        preset = PipelineConfig(
            name="Custom",
            description="Custom configuration",
            query_analysis_enabled=query_analysis,
            cot_enabled=cot,
            reranker_enabled=reranker,
            cove_mode=cove_mode,
            prompt_template=prompt_template,
            top_k=top_k,
        )

    st.divider()

    # === ADVANCED FEATURES ===
    st.markdown("### üî¨ Advanced Features")

    # A/B Comparison Mode
    st.session_state.comparison_mode = st.checkbox(
        "üîÄ A/B Comparison Mode",
        value=st.session_state.comparison_mode,
        help="Send query to 2 configs and compare side-by-side"
    )

    if st.session_state.comparison_mode:
        st.info("üí° Next query will be sent to both Baseline and Enhanced configs")

    # Session Statistics
    if st.button("üìä View Session Stats"):
        stats = st.session_state.session_stats
        if stats["total_queries"] > 0:
            st.metric("Total Queries", stats["total_queries"])
            st.metric("Avg Time", f"{stats['total_time_ms'] / stats['total_queries']:.0f}ms")

            if stats["configs_used"]:
                st.write("**Configs Used:**")
                for cfg, count in stats["configs_used"].items():
                    st.write(f"- {cfg}: {count}x")
        else:
            st.info("No queries yet")

    # Export Session
    if st.button("üíæ Export Session"):
        if st.session_state.messages:
            export_data = {
                "timestamp": datetime.now().isoformat(),
                "stats": st.session_state.session_stats,
                "messages": st.session_state.messages,
            }

            # JSON download
            st.download_button(
                label="üì• Download JSON",
                data=json.dumps(export_data, indent=2, ensure_ascii=False),
                file_name=f"ragx_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
            )

            # Markdown download
            md_content = f"# RAGx Chat Session\n\n**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
            for msg in st.session_state.messages:
                role = "**User:**" if msg["role"] == "user" else "**Assistant:**"
                md_content += f"{role}\n{msg['content']}\n\n"
                if msg["role"] == "assistant" and "sources" in msg:
                    md_content += f"*Sources: {len(msg['sources'])} documents*\n\n"

            st.download_button(
                label="üì• Download Markdown",
                data=md_content,
                file_name=f"ragx_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                mime="text/markdown",
            )
        else:
            st.info("No messages to export")

    st.divider()

    # Example Queries
    st.markdown("### üí° Example Queries")

    example_queries = {
        "üîµ Simple": [
            "Czym jest sztuczna inteligencja?",
            "Kiedy powsta≈Ça Wikipedia?",
        ],
        "üü£ Multihop": [
            "Por√≥wnaj mitologiƒô s≈Çowia≈ÑskƒÖ i nordyckƒÖ",
            "Ziemniaki vs pomidory - kt√≥ry ma wiƒôcej b≈Çonnika?",
            "Jakie sƒÖ podobie≈Ñstwa miƒôdzy kwantowƒÖ mechanikƒÖ a teoriƒÖ wzglƒôdno≈õci?",
        ],
        "üü¢ Complex": [
            "Jak rozw√≥j AI wp≈Çywa na rynek pracy i kt√≥re zawody sƒÖ najbardziej zagro≈ºone?",
        ],
    }

    for category, queries in example_queries.items():
        with st.expander(category):
            for q in queries:
                if st.button(q, key=f"example_{hash(q)}"):
                    st.session_state.example_query = q
                    st.rerun()

    st.divider()

    # Clear chat button
    if st.button("üóëÔ∏è Clear Chat"):
        st.session_state.messages = []
        st.session_state.session_stats = {
            "total_queries": 0,
            "total_time_ms": 0,
            "configs_used": {},
        }
        st.rerun()

    st.divider()

    # Connection status ‚Äì tylko na ≈ºƒÖdanie, bez ciƒÖg≈Çego health checka
    st.markdown("### Connection Status")
    if st.button("üîÑ Check connection"):
        try:
            response = requests.get(f"{api_url}/info/health", timeout=2)
            if response.ok:
                st.session_state.connection_status = {
                    "status": "ok",
                    "message": "Connected",
                }
            else:
                st.session_state.connection_status = {
                    "status": "error",
                    "message": f"API Error (status {response.status_code})",
                }
        except Exception:
            st.session_state.connection_status = {
                "status": "error",
                "message": "Not Connected",
            }

    # Wy≈õwietl ostatni znany status (bez nowych request√≥w)
    status = st.session_state.connection_status
    if status["status"] == "ok":
        st.success(f"‚úÖ {status['message']}")
    elif status["status"] == "error":
        st.error(f"‚ùå {status['message']}")
    else:
        st.info(status["message"])

# ============================================================================
# MAIN CHAT INTERFACE
# ============================================================================

st.title("üí¨ RAGx Interactive Chat")
st.caption(f"Using pipeline: **{preset.name}**")

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

        # Show metadata for assistant messages
        if message["role"] == "assistant" and "metadata" in message:
            metadata = message["metadata"]

            # Timing summary with chart
            with st.expander("‚è±Ô∏è Timing Details"):
                timings = metadata.get("timings", {})

                # Metrics row
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("Total", f"{timings.get('total_time_ms', 0):.0f}ms")
                    st.metric("Retrieval", f"{timings.get('retrieval_time_ms', 0):.0f}ms")

                with col2:
                    st.metric("Reranking", f"{timings.get('rerank_time_ms', 0):.0f}ms")
                    st.metric("Generation", f"{timings.get('llm_time_ms', 0):.0f}ms")

                with col3:
                    st.metric("Query Analysis", f"{timings.get('rewrite_time_ms', 0):.0f}ms")
                    if timings.get('cove_time_ms', 0) > 0:
                        st.metric("CoVe", f"{timings.get('cove_time_ms', 0):.0f}ms")

                # Timing breakdown chart
                st.markdown("**Breakdown:**")
                timing_data = {
                    "Query Analysis": timings.get('rewrite_time_ms', 0),
                    "Retrieval": timings.get('retrieval_time_ms', 0),
                    "Reranking": timings.get('rerank_time_ms', 0),
                    "Generation": timings.get('llm_time_ms', 0),
                    "CoVe": timings.get('cove_time_ms', 0),
                }
                # Filter out zero values
                timing_data = {k: v for k, v in timing_data.items() if v > 0}

                if timing_data and PLOTLY_AVAILABLE:
                    fig = px.bar(
                        x=list(timing_data.values()),
                        y=list(timing_data.keys()),
                        orientation='h',
                        labels={'x': 'Time (ms)', 'y': 'Phase'},
                        title='Pipeline Phase Timings'
                    )
                    fig.update_layout(height=250, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True)
                elif timing_data and not PLOTLY_AVAILABLE:
                    # Fallback: show as text
                    for phase, ms in timing_data.items():
                        st.write(f"  ‚Ä¢ {phase}: {ms:.0f}ms")

            # Pipeline info
            with st.expander("üîß Pipeline Info"):
                col1, col2 = st.columns(2)

                with col1:
                    st.write(f"**Template Used:** {metadata.get('template_used', 'N/A')}")
                    st.write(f"**Query Type:** {metadata.get('query_type', 'N/A')}")
                    st.write(f"**Multihop:** {'Yes' if metadata.get('is_multihop') else 'No'}")

                with col2:
                    st.write(f"**Candidates:** {metadata.get('num_candidates', 0)}")
                    st.write(f"**Sources Used:** {metadata.get('num_sources', 0)}")
                    phases = [p for p in metadata.get('phases', []) if p]
                    st.write(f"**Phases:** {len(phases)}")

                # Sub-queries if multihop
                if metadata.get('is_multihop') and metadata.get('sub_queries'):
                    st.markdown("**Sub-queries:**")
                    for i, sq in enumerate(metadata.get('sub_queries', []), 1):
                        st.write(f"{i}. {sq}")

            # Sources
            if "sources" in message and message["sources"]:
                with st.expander(f"üìö Sources ({len(message['sources'])})", expanded=False):
                    for i, source in enumerate(message["sources"], 1):
                        # Source header with title
                        st.markdown(f"### [{i}] {source.get('doc_title', 'Unknown')}")

                        # Metadata badges
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            if source.get('position') is not None:
                                st.caption(f"üìÑ Chunk {source.get('position', 0) + 1}/{source.get('total_chunks', '?')}")
                        with col2:
                            if source.get('retrieval_score') is not None:
                                st.caption(f"üéØ Score: {source.get('retrieval_score', 0):.3f}")
                        with col3:
                            if source.get('rerank_score') is not None:
                                st.caption(f"üìä Rerank: {source.get('rerank_score', 0):.3f}")

                        # Full text with expandable view
                        source_text = source.get('text', '')
                        if len(source_text) > 300:
                            # Skr√≥t
                            st.caption(source_text[:300] + "...")

                            # Prze≈ÇƒÖcznik do pokazania pe≈Çnego tekstu
                            show_full = st.checkbox(
                                "üìñ View full text",
                                key=f"show_full_{i}_{message.get('timestamp', '')}"
                            )
                            if show_full:
                                st.text_area(
                                    "Source text",
                                    source_text,
                                    height=200,
                                    disabled=True,
                                    label_visibility="collapsed",
                                    key=f"source_{i}_{message.get('timestamp', '')}"
                                )
                                # Copy button
                                if st.button("üìã Copy text", key=f"copy_{i}_{message.get('timestamp', '')}"):
                                    st.code(source_text, language=None)
                                    st.success("‚úì Text displayed above - use browser copy")
                            st.caption(source_text[:300] + "...")
                        else:
                            st.info(source_text)

                        # Clickable URL link
                        if source.get('url'):
                            st.markdown(f"üîó [Open Wikipedia article]({source['url']})")

                        # Additional metadata for multihop
                        if source.get('source_subquery'):
                            st.caption(f"üí° From sub-query: _{source.get('source_subquery')}_")

                        # CoVe evidence marker
                        if source.get('source') == "EVIDENCE FROM COVE":
                            st.success("‚úÖ Additional evidence from CoVe verification")

                        st.divider()

# Handle example query click
if "example_query" in st.session_state and st.session_state.example_query:
    prompt = st.session_state.example_query
    st.session_state.example_query = None  # Clear it
elif prompt := st.chat_input("Ask a question..."):
    pass  # Use the input prompt
else:
    prompt = None

if prompt:
    # Add user message to chat
    st.session_state.messages.append({
        "role": "user",
        "content": prompt,
        "timestamp": time.time()
    })

    with st.chat_message("user"):
        st.markdown(prompt)

    # Check if comparison mode is enabled
    if st.session_state.comparison_mode:
        # A/B Comparison Mode: Run both baseline and enhanced
        col1, col2 = st.columns(2)

        configs_to_compare = [
            ("baseline", PRESETS["baseline"]),
            ("enhanced_full", PRESETS["enhanced_full"]),
        ]

        results = []

        for col, (config_key, config) in zip([col1, col2], configs_to_compare):
            with col:
                with st.chat_message("assistant"):
                    st.caption(f"**{config.name}**")
                    status = st.status(f"üîÑ Processing...", expanded=True)

                    with status:
                        try:
                            st.write("üì° Calling API...")
                            result = call_rag_api(prompt, config, api_url)
                            st.write(f"‚ú® Done! {result.get('metadata', {}).get('total_time_ms', 0):.0f}ms")
                            results.append((config, result))
                        except Exception as e:
                            st.error(f"‚ùå Error: {str(e)}")
                            status.update(label="‚ùå Failed", state="error")
                            results.append((config, None))

                    status.update(label="‚úÖ Complete", state="complete", expanded=False)

                    if results[-1][1]:  # If result is not None
                        answer = results[-1][1].get("answer", "")
                        metadata = results[-1][1].get("metadata", {})

                        st.markdown(answer)

                        # Quick stats
                        st.caption(f"‚è±Ô∏è {metadata.get('total_time_ms', 0):.0f}ms | "
                                   f"üìö {metadata.get('num_sources', 0)} sources | "
                                   f"{'üîÄ Multihop' if metadata.get('is_multihop') else 'üìÑ Single'}")

        # Add comparison to chat history
        if all(r[1] for r in results):
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"**üîÄ A/B Comparison Results**\n\n"
                           f"**Baseline:** {results[0][1].get('answer', '')[:100]}...\n\n"
                           f"**Enhanced:** {results[1][1].get('answer', '')[:100]}...",
                "comparison": True,
                "results": results,
                "timestamp": time.time()
            })

            # Update stats for both
            for config, result in results:
                if result:
                    update_session_stats(
                        config.name,
                        result.get("metadata", {}).get("total_time_ms", 0)
                    )

        st.rerun()

    else:
        # Normal single config mode
        with st.chat_message("assistant"):
            # Live status display with progress
            status_container = st.status("üîÑ Processing query...", expanded=True)

            # Progress tracking
            steps = get_pipeline_steps(preset)
            enabled_steps = [s for s in steps if s[2]]  # Only enabled steps
            total_steps = len(enabled_steps)

            with status_container:
                try:
                    # Track timing
                    start_time = time.time()

                    # Show progress bar
                    progress_bar = st.progress(0.0)
                    status_text = st.empty()

                    # Simulate step progression while API is processing
                    import threading

                    api_done = threading.Event()
                    api_result = {}
                    api_error = {}

                    def api_call_thread():
                        try:
                            result = call_rag_api(prompt, preset, api_url)
                            api_result['data'] = result
                        except Exception as e:
                            api_error['error'] = e
                        finally:
                            api_done.set()

                    # Start API call in background
                    thread = threading.Thread(target=api_call_thread, daemon=True)
                    thread.start()

                    # Show progress while waiting
                    for idx, (step_key, step_msg, enabled) in enumerate(steps):
                        if enabled:
                            # Calculate progress percentage
                            progress = (idx + 1) / total_steps
                            progress_bar.progress(progress)
                            status_text.markdown(step_msg)

                            # Wait a bit for visual feedback (or until API is done)
                            for _ in range(5):  # Check every 100ms for 500ms max
                                if api_done.is_set():
                                    break
                                time.sleep(0.1)

                            if api_done.is_set():
                                break

                    # Wait for API to complete
                    api_done.wait(timeout=120)

                    # Check for errors
                    if 'error' in api_error:
                        raise api_error['error']

                    if 'data' not in api_result:
                        raise TimeoutError("API request timed out")

                    result = api_result['data']

                    # Complete progress
                    progress_bar.progress(1.0)
                    total_time = (time.time() - start_time) * 1000
                    status_text.markdown(f"‚ú® **Complete!** Total: {total_time:.0f}ms")

                except requests.exceptions.RequestException as e:
                    st.error(f"‚ùå API Error: {str(e)}")
                    status_container.update(label="‚ùå Request failed", state="error")
                    st.stop()
                except Exception as e:
                    st.error(f"‚ùå Error: {str(e)}")
                    status_container.update(label="‚ùå Processing failed", state="error")
                    st.stop()

            # Update status to complete
            status_container.update(label="‚úÖ Processing complete", state="complete", expanded=False)

            # Display answer
            answer = result.get("answer", "")
            sources = result.get("sources", [])
            metadata = result.get("metadata", {})

            st.markdown(answer)

            # Update session stats
            update_session_stats(preset.name, metadata.get("total_time_ms", 0))

            # Add to chat history
            st.session_state.messages.append({
                "role": "assistant",
                "content": answer,
                "sources": sources,
                "metadata": metadata,
                "timestamp": time.time()
            })

            st.rerun()

# ============================================================================
# FOOTER
# ============================================================================

st.sidebar.markdown("---")
st.sidebar.caption("RAGx Chat UI v1.0")
st.sidebar.caption("Built with Streamlit")
